{
    "200": {
        "file_id": 9,
        "content": "    if state_mask is None:\n        state_mask = th.zeros((b, 1, T - t), dtype=bool, device=device)\n    m_btT = get_band_diagonal_mask(t, T, maxlen, b, device).clone()  # Should be shape B, t, T\n    not_first = ~first_b11.to(device=device)\n    m_btT[:, :, :-t] &= not_first  # Zero out anything in the past if first is true\n    m_btT[:, :, :-t] &= state_mask\n    m_bhtT = m_btT[:, None].repeat_interleave(heads, dim=1)\n    m_btT = m_bhtT.reshape((b * heads), t, T)\n    # Update state_mask such that it reflects the most recent first\n    state_mask = th.cat(\n        [\n            state_mask[:, :, t:] & not_first,\n            th.ones((b, 1, min(t, T - t)), dtype=bool, device=device),\n        ],\n        dim=-1,\n    )\n    return m_btT, state_mask\nclass MaskedAttention(nn.Module):\n    \"\"\"\n    Transformer self-attention layer that removes frames from previous episodes from the hidden state under certain constraints.\n    The constraints are:\n    - The \"first\" flag can only be true for the first timestep of each batch. An assert will fire if other timesteps have first = True.",
        "type": "code",
        "location": "/lib/masked_attention.py:75-102"
    },
    "201": {
        "file_id": 9,
        "content": "This code is creating a mask for self-attention in transformer layers. It ensures that frames from previous episodes are not considered in the attention calculation for each episode. The mask is generated based on the \"first\" flag, which indicates if it's the first timestep of each batch, and the state_mask to exclude past frames.",
        "type": "comment"
    },
    "202": {
        "file_id": 9,
        "content": "    input_size: The dimension of the input (which also happens to be the size of the output)\n    memory_size: The number of frames to keep in the inner state. Note that when attending, we will be able to attend\n                 to both the frames in the inner state (which presumably won't have gradients anymore) and the frames\n                 in the batch. \"mask\" for some additional considerations on this.\n    heads: The number of attention heads to use. Note that we will split the input into this number of heads, so\n           input_size needs to be divisible by heads.\n    timesteps: number of timesteps with which we'll be taking gradient\n    mask: Can be \"none\" or \"clipped_causal\". \"clipped_causal\" is a normal causal mask but solves the following minor problem:\n        if you have a state of length 128 and a batch of 128 frames, then the first frame of your batch will be able to\n        attend to 128 previous frames, but the last one will be able to attend to 255 previous frames. In this example,",
        "type": "code",
        "location": "/lib/masked_attention.py:104-113"
    },
    "203": {
        "file_id": 9,
        "content": "The code is describing the parameters and considerations of a masked attention mechanism. The input size, memory size, number of heads, timesteps, and mask are explained. The memory size allows attending to both inner state frames and batch frames, while the mask option handles potential imbalances between the first and last frames' attending capabilities.",
        "type": "comment"
    },
    "204": {
        "file_id": 9,
        "content": "        \"clipped_causal\" will make it so that the last frame can only attend to 128 previous frames, so that there is no\n        bias coming from the position in the batch. None simply allows you to attend to any frame in the state + batch,\n        which means you can also attend to future frames.\n    \"\"\"\n    @store_args\n    def __init__(\n        self,\n        input_size,\n        memory_size: int,\n        heads: int,\n        timesteps: int,\n        mask: str = \"clipped_causal\",\n        init_scale=1,\n        norm=\"none\",\n        log_scope=\"sa\",\n        use_muP_factor=False,\n    ):\n        super().__init__()\n        assert mask in {\"none\", \"clipped_causal\"}\n        assert memory_size >= 0\n        self.maxlen = memory_size - timesteps\n        if mask == \"none\":\n            mask = None\n        self.orc_attn = xf.All2All(heads, self.maxlen, mask=mask is not None)\n        self.orc_block = xf.SelfAttentionLayer(\n            input_size,\n            self.orc_attn,\n            scale=init_scale,\n            relattn=True,\n            cache_keep_len=self.maxlen,",
        "type": "code",
        "location": "/lib/masked_attention.py:114-147"
    },
    "205": {
        "file_id": 9,
        "content": "The function initializes an object for masked attention. It takes in parameters such as input size, memory size, number of heads, timesteps, and a mask option ('clipped_causal' or 'none'). The maximum length is calculated based on the memory size and timesteps. If the mask option is set to 'none', the mask parameter is set to None. An All2All object for attention is created with heads, maxlen, and the mask value. Finally, a SelfAttentionLayer object is initialized with input size, the All2All attention object, and other parameters such as scale, relattn, and cache_keep_len set accordingly.",
        "type": "comment"
    },
    "206": {
        "file_id": 9,
        "content": "            norm=norm,\n            log_scope=log_scope,\n            use_muP_factor=use_muP_factor,\n        )\n    def initial_state(self, batchsize: int, device=None):\n        \"\"\"Return the initial state mask (None) and the initial state of the transformer (zerod out keys and queries)\"\"\"\n        state = self.orc_block.initial_state(batchsize, initial_T=self.maxlen)\n        state_mask = None\n        if device is not None:\n            state = tree_map(lambda x: x.to(device), state)\n        return state_mask, state\n    def forward(self, input_bte, first_bt, state):\n        \"\"\"Forward propagation of a single layer\"\"\"\n        state_mask, xf_state = state\n        t = first_bt.shape[1]\n        if self.mask == \"clipped_causal\":\n            new_mask, state_mask = get_mask(\n                first_b11=first_bt[:, [[0]]],\n                state_mask=state_mask,\n                t=t,\n                T=t + self.maxlen,\n                maxlen=self.maxlen,\n                heads=self.heads,\n                device=input_bte.device,",
        "type": "code",
        "location": "/lib/masked_attention.py:148-173"
    },
    "207": {
        "file_id": 9,
        "content": "This code defines a class for Masked Attention, which has methods for initializing the state, forward propagation of a single layer, and defining the mask type. The initial_state method returns the initial state mask (None) and the initial state of the transformer with keys and queries zeros out. The forward method performs forward propagation of a single layer using the input, first_bt, and state as inputs. If the mask type is \"clipped_causal\", it applies a specific mask to the input.",
        "type": "comment"
    },
    "208": {
        "file_id": 9,
        "content": "            )\n            self.orc_block.attn.mask = new_mask\n        output, xf_state = self.orc_block(input_bte, xf_state)\n        return output, (state_mask, xf_state)\n    def get_log_keys(self):\n        # These are logged in xf.SelfAttentionLayer\n        return [f\"activation_{stat}/{self.log_scope}/{k}\" for k in [\"K\", \"Q\", \"V\", \"A\", \"Aproj\"] for stat in [\"mean\", \"std\"]]",
        "type": "code",
        "location": "/lib/masked_attention.py:174-182"
    },
    "209": {
        "file_id": 9,
        "content": "This code is defining a method in the class and returning comments for the code block. The method seems to be related to attention mechanism, where it applies masking to the input and returns output and state information. The log keys are defined as well for further logging purposes.",
        "type": "comment"
    },
    "210": {
        "file_id": 10,
        "content": "/lib/minecraft_util.py",
        "type": "filepath"
    },
    "211": {
        "file_id": 10,
        "content": "The code uses a decorator function to compute normalized entropy from categorical head outputs, considering masks and ignoring single-option cases. It also calculates the entropy of categorical and diagonal Gaussian action heads within a module by iterating over key-value pairs and returns average entropy.",
        "type": "summary"
    },
    "212": {
        "file_id": 10,
        "content": "import functools\nimport inspect\nfrom typing import Optional, Tuple\nimport numpy as np\nimport torch\nfrom lib.action_head import (CategoricalActionHead, DiagGaussianActionHead,\n                             DictActionHead)\ndef store_args(method):\n    \"\"\"Stores provided method args as instance attributes.\"\"\"\n    argspec = inspect.getfullargspec(method)\n    defaults = {}\n    if argspec.defaults is not None:\n        defaults = dict(zip(argspec.args[-len(argspec.defaults) :], argspec.defaults))\n    if argspec.kwonlydefaults is not None:\n        defaults.update(argspec.kwonlydefaults)\n    arg_names = argspec.args[1:]\n    @functools.wraps(method)\n    def wrapper(*positional_args, **keyword_args):\n        self = positional_args[0]\n        # Get default arg values\n        args = defaults.copy()\n        # Add provided arg values\n        for name, value in zip(arg_names, positional_args[1:]):\n            args[name] = value\n        args.update(keyword_args)\n        self.__dict__.update(args)\n        return method(*positional_args, **keyword_args)",
        "type": "code",
        "location": "/lib/minecraft_util.py:1-32"
    },
    "213": {
        "file_id": 10,
        "content": "This code defines a decorator function `store_args` that takes a method as input, and when the decorated method is called, it stores its arguments as instance attributes of the class. It also handles default argument values and keyword-only arguments.",
        "type": "comment"
    },
    "214": {
        "file_id": 10,
        "content": "    return wrapper\ndef get_norm_entropy_from_cat_head(module, name, masks, logits):\n    # Note that the mask has already been applied to the logits at this point\n    entropy = -torch.sum(torch.exp(logits) * logits, dim=-1)\n    if name in masks:\n        n = torch.sum(masks[name], dim=-1, dtype=torch.float)\n        norm_entropy = entropy / torch.log(n)\n        # When the mask only allows one option the normalized entropy makes no sense\n        # as it is basically both maximal (the distribution is as uniform as it can be)\n        # and minimal (there is no variance at all).\n        # A such, we ignore them for purpose of calculating entropy.\n        zero = torch.zeros_like(norm_entropy)\n        norm_entropy = torch.where(n.eq(1.0), zero, norm_entropy)\n        count = n.not_equal(1.0).int()\n    else:\n        n = torch.tensor(logits.shape[-1], dtype=torch.float)\n        norm_entropy = entropy / torch.log(n)\n        count = torch.ones_like(norm_entropy, dtype=torch.int)\n    # entropy is per-entry, still of size self.output_shape[:-1]; we need to reduce of the rest of it.",
        "type": "code",
        "location": "/lib/minecraft_util.py:34-55"
    },
    "215": {
        "file_id": 10,
        "content": "This code calculates the normalized entropy from categorical head outputs and applies a mask if necessary. It divides the entropy by the log of the number of possible options, ignoring cases where only one option is available to avoid nonsense results. The count variable keeps track of how many times the condition for ignoring an option has been met.",
        "type": "comment"
    },
    "216": {
        "file_id": 10,
        "content": "    for _ in module.output_shape[:-1]:\n        norm_entropy = norm_entropy.sum(dim=-1)\n        count = count.sum(dim=-1)\n    return norm_entropy, count\ndef get_norm_cat_entropy(module, masks, logits, template) -> Tuple[torch.Tensor, torch.Tensor]:\n    entropy_sum = torch.zeros_like(template, dtype=torch.float)\n    counts = torch.zeros_like(template, dtype=torch.int)\n    for k, subhead in module.items():\n        if isinstance(subhead, DictActionHead):\n            entropy, count = get_norm_cat_entropy(subhead, masks, logits[k], template)\n        elif isinstance(subhead, CategoricalActionHead):\n            entropy, count = get_norm_entropy_from_cat_head(subhead, k, masks, logits[k])\n        else:\n            continue\n        entropy_sum += entropy\n        counts += count\n    return entropy_sum, counts\ndef get_diag_guassian_entropy(module, logits, template) -> Optional[torch.Tensor]:\n    entropy_sum = torch.zeros_like(template, dtype=torch.float)\n    count = torch.zeros(1, device=template.device, dtype=torch.int)",
        "type": "code",
        "location": "/lib/minecraft_util.py:56-79"
    },
    "217": {
        "file_id": 10,
        "content": "This code calculates the entropy of categorical and diagonal Gaussian action heads in a given module and returns the total entropy and counts.",
        "type": "comment"
    },
    "218": {
        "file_id": 10,
        "content": "    for k, subhead in module.items():\n        if isinstance(subhead, DictActionHead):\n            entropy_sum += get_diag_guassian_entropy(subhead, logits[k], template)\n        elif isinstance(subhead, DiagGaussianActionHead):\n            entropy_sum += module.entropy(logits)\n        else:\n            continue\n        count += 1\n    return entropy_sum / count",
        "type": "code",
        "location": "/lib/minecraft_util.py:80-88"
    },
    "219": {
        "file_id": 10,
        "content": "Iterates over each key-value pair in the module, adds entropy from DiagGaussianActionHead or DictActionHead to entropy_sum, and returns the average entropy.",
        "type": "comment"
    },
    "220": {
        "file_id": 11,
        "content": "/lib/misc.py",
        "type": "filepath"
    },
    "221": {
        "file_id": 11,
        "content": "Both comments discuss data processing tasks, with Comment A focusing on calculating and dividing products in a list 'x', while Comment B describes a function for reshaping input data, considering exceptions and undo functions, and utilizing a 'known' dictionary for shape inference.",
        "type": "summary"
    },
    "222": {
        "file_id": 11,
        "content": "import numpy as np\nimport torch as th\ndef intprod(xs):\n    \"\"\"\n    Product of a sequence of integers\n    \"\"\"\n    out = 1\n    for x in xs:\n        out *= x\n    return out\ndef safezip(*args):\n    \"\"\"\n    Check that lengths of sequences are the same, then zip them\n    \"\"\"\n    args = [list(a) for a in args]\n    n = len(args[0])\n    for arg in args[1:]:\n        assert len(arg) == n, f\"length mismatch: {list(map(len, args))}\"\n    return list(zip(*args))\ndef transpose(x, before, after):\n    \"\"\"\n    Usage: x_bca = transpose(x_abc, 'abc', 'bca')\n    \"\"\"\n    assert sorted(before) == sorted(after), f\"cannot transpose {before} to {after}\"\n    assert x.ndim == len(\n        before\n    ), f\"before spec '{before}' has length {len(before)} but x has {x.ndim} dimensions: {tuple(x.shape)}\"\n    return x.permute(tuple(before.index(i) for i in after))\ndef transpose_undo(x, before, after, *, undo=None):\n    \"\"\"\n    Usage:\n    x_bca, undo = transpose_undo(x_abc, 'abc', 'bca')\n    x_bca = fully_connected_layer(x_bca)\n    x_abc = undo(x_bca)\n    \"\"\"",
        "type": "code",
        "location": "/lib/misc.py:1-43"
    },
    "223": {
        "file_id": 11,
        "content": "The code contains several functions related to data manipulation, such as calculating the product of a sequence of integers (`intprod`), checking and zipping lengths of sequences (`safezip`), transposing data with given before and after specifications (`transpose`), and undoing a data transposition (`transpose_undo`).",
        "type": "comment"
    },
    "224": {
        "file_id": 11,
        "content": "    return (\n        transpose(x, before, after),\n        compose_undo(undo, lambda x: transpose(x, before=after, after=before)),\n    )\ndef compose_undo(u1, u2):\n    assert u2 is not None\n    if u1 is None:\n        return u2\n    def u(x):\n        x = u2(x)\n        x = u1(x)\n        return x\n    return u\nNO_BIND = \"__nobind\"\ndef _parse_reshape_str(s, kind):\n    assert kind in (\"before\", \"after\")\n    result = []\n    n_underscores = 0\n    for i, part in enumerate(s.split(\",\")):\n        part = part.strip()\n        if part == \"?\" and kind == \"before\":\n            result.append([f\"__{i}\"])\n        elif part == \"_\":\n            result.append([f\"{NO_BIND}_{n_underscores}\"])\n            n_underscores += 1\n        else:\n            result.append([term.strip() for term in part.split(\"*\")])\n    return result\ndef _infer_part(part, concrete_dim, known, index, full_shape):\n    if type(part) is int:\n        return part\n    assert isinstance(part, list), part\n    lits = []\n    syms = []\n    for term in part:\n        if type(term) is int:",
        "type": "code",
        "location": "/lib/misc.py:44-89"
    },
    "225": {
        "file_id": 11,
        "content": "Function `transpose` takes an input tensor, and a list of tuples specifying the axes to permute. It returns the transposed tensor and a function that undoes the transpose operation.\nFunction `compose_undo` combines two transformation functions into a single one that applies them in reverse order. If either is None, it simply returns the other. Otherwise, it creates an anonymous function that first applies the second transformation, then the first, and finally returns the result.\nString `NO_BIND` is used as a placeholder when a dimension cannot be bound to a specific variable.\nFunction `_parse_reshape_str` parses a string of the form \"x,*y,?z\" where x, y, and z are integers or '?' symbols. It returns a list containing three lists: the first contains '?' characters for 'before', '_' characters for 'after', and actual numbers for 'none'. The second contains actual numbers for 'before', and the third contains actual numbers for 'after'.\nFunction `_infer_part` infers the part of the tensor shape to be used based on the type of the input. If it is an integer, it returns that integer. Otherwise, it processes a list of terms, handling integers and strings containing '*' symbols differently.",
        "type": "comment"
    },
    "226": {
        "file_id": 11,
        "content": "            lits.append(term)\n        elif type(term) is str:\n            syms.append(term)\n        else:\n            raise TypeError(f\"got {type(term)} but expected int or str\")\n    int_part = 1\n    for x in lits:\n        int_part *= x\n    if len(syms) == 0:\n        return int_part\n    elif len(syms) == 1 and concrete_dim is not None:\n        assert concrete_dim % int_part == 0, f\"{concrete_dim} % {int_part} != 0 (at index {index}, full shape is {full_shape})\"\n        v = concrete_dim // int_part\n        if syms[0] in known:\n            assert (\n                known[syms[0]] == v\n            ), f\"known value for {syms[0]} is {known[syms[0]]} but found value {v} at index {index} (full shape is {full_shape})\"\n        else:\n            known[syms[0]] = v\n        return concrete_dim\n    else:\n        for i in range(len(syms)):\n            if syms[i] in known:\n                syms[i] = known[syms[i]]\n            else:\n                try:\n                    syms[i] = int(syms[i])\n                except ValueError:\n                    pass",
        "type": "code",
        "location": "/lib/misc.py:90-118"
    },
    "227": {
        "file_id": 11,
        "content": "This function takes a term, checks if it's an int or str, and performs calculations based on the input type. If int, it multiplies all literals (int or float) and returns the result. If str, it checks if there's only one symbol and concrete_dim is given. It asserts that concrete_dim is divisible by int_part and calculates v. If the symbol is already in known values, it asserts the known value matches. If not, it adds the symbol to known with its calculated value. Finally, if there are multiple symbols, it iterates through them and converts strings to ints.",
        "type": "comment"
    },
    "228": {
        "file_id": 11,
        "content": "        return lits + syms\ndef _infer_step(args):\n    known, desc, shape = args\n    new_known = known.copy()\n    new_desc = desc.copy()\n    for i in range(len(desc)):\n        if shape is None:\n            concrete_dim = None\n        else:\n            concrete_dim = shape[i]\n        new_desc[i] = _infer_part(part=desc[i], concrete_dim=concrete_dim, known=new_known, index=i, full_shape=shape)\n    return new_known, new_desc, shape\ndef _infer(known, desc, shape):\n    if shape is not None:\n        assert len(desc) == len(shape), f\"desc has length {len(desc)} but shape has length {len(shape)} (shape={shape})\"\n    known, desc, shape = fixed_point(_infer_step, (known, desc, shape))\n    return desc, known\ndef fixed_point(f, x, eq=None):\n    if eq is None:\n        eq = lambda a, b: a == b\n    while True:\n        new_x = f(x)\n        if eq(x, new_x):\n            return x\n        else:\n            x = new_x\ndef _infer_question_mark(x, total_product):\n    try:\n        question_mark_index = x.index([\"?\"])\n    except ValueError:\n        return x",
        "type": "code",
        "location": "/lib/misc.py:119-157"
    },
    "229": {
        "file_id": 11,
        "content": "This function takes an existing list `lits` and a symbol `syms` and returns a new list where the `syms` occur after all elements in `lits`. The `_infer_step()` function takes known values, description, and shape as arguments. It creates copies of the new known and description lists and loops through each element in the description list. If a specific shape is provided, it assigns the corresponding dimension to `concrete_dim`. Then, it calls `_infer_part()` with the part, concrete dimension, known values, index, and full shape as arguments. The function returns the new known values, description list, and shape. The `fixed_point()` function uses a lambda function to check for equality between two inputs. It continues to apply the given function to the input until it reaches a fixed point where the input remains unchanged. Lastly, `_infer_question_mark()` function tries to find the index of \"?\" in the list and returns the list if found.",
        "type": "comment"
    },
    "230": {
        "file_id": 11,
        "content": "    observed_product = 1\n    for i in range(len(x)):\n        if i != question_mark_index:\n            assert type(x[i]) is int, f\"when there is a question mark, there can be no other unknown values (full list: {x})\"\n            observed_product *= x[i]\n    assert (\n        observed_product and total_product % observed_product == 0\n    ), f\"{total_product} is not divisible by {observed_product}\"\n    value = total_product // observed_product\n    x = x.copy()\n    x[question_mark_index] = value\n    return x\ndef _ground(x, known, infer_question_mark_with=None):\n    x, known = _infer(known=known, desc=x, shape=None)\n    if infer_question_mark_with:\n        x = _infer_question_mark(x, infer_question_mark_with)\n    for part in x:\n        assert type(part) is int, f\"cannot infer value of {part}\"\n    return x\ndef _handle_ellipsis(x, before, after):\n    ell = [\"...\"]\n    try:\n        i = before.index(ell)\n        l = len(x.shape) - len(before) + 1\n        ellipsis_value = x.shape[i : i + l]\n        ellipsis_value = list(ellipsis_value)",
        "type": "code",
        "location": "/lib/misc.py:158-187"
    },
    "231": {
        "file_id": 11,
        "content": "- Calculate product of known values in list 'x'\n- Assert that the total product is divisible by observed product and return error message if not\n- Update list 'x' with calculated value for the question mark index and return it",
        "type": "comment"
    },
    "232": {
        "file_id": 11,
        "content": "        before = before[:i] + ellipsis_value + before[i + 1 :]\n    except ValueError:\n        pass\n    try:\n        i = after.index(ell)\n        after = after[:i] + ellipsis_value + after[i + 1 :]\n    except ValueError:\n        pass\n    except UnboundLocalError as e:\n        raise ValueError(\"there cannot be an ellipsis in 'after' unless there is an ellipsis in 'before'\") from e\n    return before, after\ndef reshape_undo(inp, before, after, *, undo=None, known=None, **kwargs):\n    \"\"\"\n    Usage:\n    x_Bhwse, undo = reshape_undo(\n        x_bthwe,\n        'b, t, ..., stride*e',\n        'b*t, ..., stride, e',\n        stride=7\n    )\n    x_Bhwse = do_some_stuff(x_Bhwse)\n    x_bthwe = undo(x_Bhwse)\n    It's necessary to pass known values as keywords only\n    when they can't be inferred from the shape.\n    (Eg. in the above example we needed to pass\n    stride but not b, t, or e, since those can be determined from\n    inp.shape once stride is known.)\n    \"\"\"\n    if known:\n        known = {**kwargs, **known}\n    else:\n        known = kwargs",
        "type": "code",
        "location": "/lib/misc.py:188-223"
    },
    "233": {
        "file_id": 11,
        "content": "The code performs shape reshaping operations and handles any exceptions that may occur during the process. It takes input, initial 'before' and 'after' shapes as arguments, and optional 'undo' and 'known' parameters. If 'known' is provided, it becomes a dictionary of known values to help with shape inference. The function returns reshaped input and an 'undo' function for reverting the reshape operation.",
        "type": "comment"
    },
    "234": {
        "file_id": 11,
        "content": "    assert type(before) is type(after), f\"{type(before)} != {type(after)}\"\n    assert isinstance(inp, (th.Tensor, np.ndarray)), f\"require tensor or ndarray but got {type(inp)}\"\n    assert isinstance(before, (str, list)), f\"require str or list but got {type(before)}\"\n    if isinstance(before, str):\n        before = _parse_reshape_str(before, \"before\")\n        after = _parse_reshape_str(after, \"after\")\n        before, after = _handle_ellipsis(inp, before, after)\n    before_saved, after_saved = before, after\n    before, known = _infer(known=known, desc=before, shape=inp.shape)\n    before = _ground(before, known, product(inp.shape))\n    after = _ground(after, known, product(inp.shape))\n    known = {k: v for k, v in known.items() if not k.startswith(NO_BIND)}\n    assert tuple(inp.shape) == tuple(before), f\"expected shape {before} but got shape {inp.shape}\"\n    assert product(inp.shape) == product(\n        after\n    ), f\"cannot reshape {inp.shape} to {after} because the number of elements does not match\"\n    return (",
        "type": "code",
        "location": "/lib/misc.py:224-240"
    },
    "235": {
        "file_id": 11,
        "content": "Ensures input types are correct and parses reshape string if input is a string. Infers the shape of the input, grounds it, and removes any bindings marked with NO_BIND. Asserts that the shapes match and returns the result.",
        "type": "comment"
    },
    "236": {
        "file_id": 11,
        "content": "        inp.reshape(after),\n        compose_undo(undo, lambda inp: reshape(inp, after_saved, before_saved, known=known)),\n    )\ndef reshape(*args, **kwargs):\n    \"\"\"\n    Please see the documenation for reshape_undo.\n    \"\"\"\n    x, _ = reshape_undo(*args, **kwargs)\n    return x\ndef product(xs, one=1):\n    result = one\n    for x in xs:\n        result = result * x\n    return result\ndef exact_div(a, b):\n    assert a % b == 0, f\"{a} is not divisible by {b}\"\n    return a // b",
        "type": "code",
        "location": "/lib/misc.py:241-263"
    },
    "237": {
        "file_id": 11,
        "content": "The code contains functions for reshaping arrays, calculating products of a list of numbers, and performing an exact division.",
        "type": "comment"
    },
    "238": {
        "file_id": 12,
        "content": "/lib/mlp.py",
        "type": "filepath"
    },
    "239": {
        "file_id": 12,
        "content": "MLP class defines a neural network with specified input, hidden, and output layers. It uses normed linear layers and applies the specified activation function to hidden layers.",
        "type": "summary"
    },
    "240": {
        "file_id": 12,
        "content": "import torch as th\nfrom torch import nn\nfrom lib import misc\nfrom lib import torch_util as tu\nclass MLP(nn.Module):\n    def __init__(self, insize, nhidlayer, outsize, hidsize, hidactiv, dtype=th.float32):\n        super().__init__()\n        self.insize = insize\n        self.nhidlayer = nhidlayer\n        self.outsize = outsize\n        in_sizes = [insize] + [hidsize] * nhidlayer\n        out_sizes = [hidsize] * nhidlayer + [outsize]\n        self.layers = nn.ModuleList(\n            [tu.NormedLinear(insize, outsize, dtype=dtype) for (insize, outsize) in misc.safezip(in_sizes, out_sizes)]\n        )\n        self.hidactiv = hidactiv\n    def forward(self, x):\n        *hidlayers, finallayer = self.layers\n        for layer in hidlayers:\n            x = layer(x)\n            x = self.hidactiv(x)\n        x = finallayer(x)\n        return x\n    @property\n    def output_shape(self):\n        return (self.outsize,)",
        "type": "code",
        "location": "/lib/mlp.py:1-31"
    },
    "241": {
        "file_id": 12,
        "content": "MLP class defines a neural network with specified input, hidden, and output layers. It uses normed linear layers and applies the specified activation function to hidden layers.",
        "type": "comment"
    },
    "242": {
        "file_id": 13,
        "content": "/lib/normalize_ewma.py",
        "type": "filepath"
    },
    "243": {
        "file_id": 13,
        "content": "The NormalizeEwma module normalizes data across dimensions, calculates debiased mean and variance, and provides methods for normalization and denormalization. It maintains running mean and variance for input vectors during training while avoiding backpropagation issues.",
        "type": "summary"
    },
    "244": {
        "file_id": 13,
        "content": "import numpy as np\nimport torch\nimport torch.nn as nn\nclass NormalizeEwma(nn.Module):\n    \"\"\"Normalize a vector of observations - across the first norm_axes dimensions\"\"\"\n    def __init__(self, input_shape, norm_axes=2, beta=0.99999, per_element_update=False, epsilon=1e-5):\n        super().__init__()\n        self.input_shape = input_shape\n        self.norm_axes = norm_axes\n        self.epsilon = epsilon\n        self.beta = beta\n        self.per_element_update = per_element_update\n        self.running_mean = nn.Parameter(torch.zeros(input_shape, dtype=torch.float), requires_grad=False)\n        self.running_mean_sq = nn.Parameter(torch.zeros(input_shape, dtype=torch.float), requires_grad=False)\n        self.debiasing_term = nn.Parameter(torch.tensor(0.0, dtype=torch.float), requires_grad=False)\n    def reset_parameters(self):\n        self.running_mean.zero_()\n        self.running_mean_sq.zero_()\n        self.debiasing_term.zero_()\n    def running_mean_var(self):\n        debiased_mean = self.running_mean / self.debiasing_term.clamp(min=self.epsilon)",
        "type": "code",
        "location": "/lib/normalize_ewma.py:1-28"
    },
    "245": {
        "file_id": 13,
        "content": "NormalizeEwma is an EWMA (Exponential Weighted Moving Average) normalization module for vectors of observations. It normalizes the data across specific dimensions, with optional per-element update and debiasing term.",
        "type": "comment"
    },
    "246": {
        "file_id": 13,
        "content": "        debiased_mean_sq = self.running_mean_sq / self.debiasing_term.clamp(min=self.epsilon)\n        debiased_var = (debiased_mean_sq - debiased_mean ** 2).clamp(min=1e-2)\n        return debiased_mean, debiased_var\n    def forward(self, input_vector):\n        # Make sure input is float32\n        input_vector = input_vector.to(torch.float)\n        if self.training:\n            # Detach input before adding it to running means to avoid backpropping through it on\n            # subsequent batches.\n            detached_input = input_vector.detach()\n            batch_mean = detached_input.mean(dim=tuple(range(self.norm_axes)))\n            batch_sq_mean = (detached_input ** 2).mean(dim=tuple(range(self.norm_axes)))\n            if self.per_element_update:\n                batch_size = np.prod(detached_input.size()[: self.norm_axes])\n                weight = self.beta ** batch_size\n            else:\n                weight = self.beta\n            self.running_mean.mul_(weight).add_(batch_mean * (1.0 - weight))\n            self.running_mean_sq.mul_(weight).add_(batch_sq_mean * (1.0 - weight))",
        "type": "code",
        "location": "/lib/normalize_ewma.py:29-51"
    },
    "247": {
        "file_id": 13,
        "content": "This code calculates the debiased mean and variance of input vectors for each batch while training. It normalizes the input to float32, updates running means and squared means with detached inputs, and applies weighted averages to avoid backpropagation through subsequent batches.",
        "type": "comment"
    },
    "248": {
        "file_id": 13,
        "content": "            self.debiasing_term.mul_(weight).add_(1.0 * (1.0 - weight))\n        mean, var = self.running_mean_var()\n        return (input_vector - mean[(None,) * self.norm_axes]) / torch.sqrt(var)[(None,) * self.norm_axes]\n    def denormalize(self, input_vector):\n        \"\"\"Transform normalized data back into original distribution\"\"\"\n        mean, var = self.running_mean_var()\n        return input_vector * torch.sqrt(var)[(None,) * self.norm_axes] + mean[(None,) * self.norm_axes]",
        "type": "code",
        "location": "/lib/normalize_ewma.py:52-60"
    },
    "249": {
        "file_id": 13,
        "content": "This class provides methods to normalize and denormalize data. It also maintains running mean and variance.",
        "type": "comment"
    },
    "250": {
        "file_id": 14,
        "content": "/lib/policy.py",
        "type": "filepath"
    },
    "251": {
        "file_id": 14,
        "content": "The code includes classes for image preprocessing, reinforcement learning with optional parameters, and a MinecraftAgentPolicy network using PyTorch neural networks. It handles policy decisions, actions, and probabilities in the policy network while utilizing 3D convolution layers for reinforcement learning models.",
        "type": "summary"
    },
    "252": {
        "file_id": 14,
        "content": "from copy import deepcopy\nfrom email import policy\nfrom typing import Dict, Optional\nimport numpy as np\nimport torch as th\nfrom gym3.types import DictType\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom lib.action_head import make_action_head\nfrom lib.action_mapping import CameraHierarchicalMapping\nfrom lib.impala_cnn import ImpalaCNN\nfrom lib.normalize_ewma import NormalizeEwma\nfrom lib.scaled_mse_head import ScaledMSEHead\nfrom lib.tree_util import tree_map\nfrom lib.util import FanInInitReLULayer, ResidualRecurrentBlocks\nfrom lib.misc import transpose\nclass ImgPreprocessing(nn.Module):\n    \"\"\"Normalize incoming images.\n    :param img_statistics: remote path to npz file with a mean and std image. If specified\n        normalize images using this.\n    :param scale_img: If true and img_statistics not specified, scale incoming images by 1/255.\n    \"\"\"\n    def __init__(self, img_statistics: Optional[str] = None, scale_img: bool = True):\n        super().__init__()\n        self.img_mean = None\n        if img_statistics is not None:",
        "type": "code",
        "location": "/lib/policy.py:1-32"
    },
    "253": {
        "file_id": 14,
        "content": "This code defines a class called \"ImgPreprocessing\" which is used to normalize incoming images. It has an optional parameter for img_statistics, a remote path to a npz file containing mean and std image values. If img_statistics is provided, the images are normalized using those values. Otherwise, if no img_statistics is provided but scale_img is True, the images are scaled by 1/255. The class inherits from nn.Module which allows it to be used as part of a neural network in PyTorch. The code also initializes an instance variable self.img_mean to None.",
        "type": "comment"
    },
    "254": {
        "file_id": 14,
        "content": "            img_statistics = dict(**np.load(img_statistics))\n            self.img_mean = nn.Parameter(th.Tensor(img_statistics[\"mean\"]), requires_grad=False)\n            self.img_std = nn.Parameter(th.Tensor(img_statistics[\"std\"]), requires_grad=False)\n        else:\n            self.ob_scale = 255.0 if scale_img else 1.0\n    def forward(self, img):\n        x = img.to(dtype=th.float32)\n        if self.img_mean is not None:\n            x = (x - self.img_mean) / self.img_std\n        else:\n            x = x / self.ob_scale\n        return x\nclass ImgObsProcess(nn.Module):\n    \"\"\"ImpalaCNN followed by a linear layer.\n    :param cnn_outsize: impala output dimension\n    :param output_size: output size of the linear layer.\n    :param dense_init_norm_kwargs: kwargs for linear FanInInitReLULayer\n    :param init_norm_kwargs: kwargs for 2d and 3d conv FanInInitReLULayer\n    \"\"\"\n    def __init__(\n        self,\n        cnn_outsize: int,\n        output_size: int,\n        dense_init_norm_kwargs: Dict = {},\n        init_norm_kwargs: Dict = {},",
        "type": "code",
        "location": "/lib/policy.py:33-62"
    },
    "255": {
        "file_id": 14,
        "content": "This code defines a class named \"ImgObsProcess\" which is a subclass of nn.Module used for preprocessing images and observations. It loads image statistics (mean and std) from a file or uses default scale values based on the provided \"scale_img\". The forward method normalizes the input image by subtracting mean and dividing by std if img_mean and img_std are not None, otherwise it divides by ob_scale. The class also accepts parameters for creating an instance of ImpalaCNN followed by a linear layer.",
        "type": "comment"
    },
    "256": {
        "file_id": 14,
        "content": "        **kwargs,\n    ):\n        super().__init__()\n        self.cnn = ImpalaCNN(\n            outsize=cnn_outsize,\n            init_norm_kwargs=init_norm_kwargs,\n            dense_init_norm_kwargs=dense_init_norm_kwargs,\n            **kwargs,\n        )\n        self.linear = FanInInitReLULayer(\n            cnn_outsize,\n            output_size,\n            layer_type=\"linear\",\n            **dense_init_norm_kwargs,\n        )\n    def forward(self, img):\n        return self.linear(self.cnn(img))\nclass MinecraftPolicy(nn.Module):\n    \"\"\"\n    :param recurrence_type:\n        None                - No recurrence, adds no extra layers\n        lstm                - (Depreciated). Singular LSTM\n        multi_layer_lstm    - Multi-layer LSTM. Uses n_recurrence_layers to determine number of consecututive LSTMs\n            Does NOT support ragged batching\n        multi_masked_lstm   - Multi-layer LSTM that supports ragged batching via the first vector. This model is slower\n            Uses n_recurrence_layers to determine number of consecututive LSTMs",
        "type": "code",
        "location": "/lib/policy.py:63-91"
    },
    "257": {
        "file_id": 14,
        "content": "This code defines a class called \"Policy\" with an initializer and a forward method. The initializer takes various parameters, creates an ImpalaCNN and FanInInitReLULayer layers, and initializes the CNN layer with given parameters. The forward method applies these layers to input images and returns the result.\nThe code also defines a class called \"MinecraftPolicy\" that extends nn.Module and takes recurrence_type as parameter. It doesn't have any methods defined.",
        "type": "comment"
    },
    "258": {
        "file_id": 14,
        "content": "        transformer         - Dense transformer\n    :param init_norm_kwargs: kwargs for all FanInInitReLULayers.\n    \"\"\"\n    def __init__(\n        self,\n        recurrence_type=\"lstm\",\n        impala_width=1,\n        impala_chans=(16, 32, 32),\n        obs_processing_width=256,\n        hidsize=512,\n        single_output=False,  # True if we don't need separate outputs for action/value outputs\n        img_shape=None,\n        scale_input_img=True,\n        only_img_input=False,\n        init_norm_kwargs={},\n        impala_kwargs={},\n        # Unused argument assumed by forc.\n        input_shape=None,  # pylint: disable=unused-argument\n        active_reward_monitors=None,\n        img_statistics=None,\n        first_conv_norm=False,\n        diff_mlp_embedding=False,\n        attention_mask_style=\"clipped_causal\",\n        attention_heads=8,\n        attention_memory_size=2048,\n        use_pointwise_layer=True,\n        pointwise_ratio=4,\n        pointwise_use_activation=False,\n        n_recurrence_layers=1,\n        recurrence_is_residual=True,",
        "type": "code",
        "location": "/lib/policy.py:92-122"
    },
    "259": {
        "file_id": 14,
        "content": "This function is used to initialize an object of the class \"Policy\" which appears to be a deep learning model for reinforcement learning. The model can take both image and observation inputs, and uses a Dense transformer as part of its architecture. There are many optional parameters such as recurrence_type, impala_width, obs_processing_width, hidsize, single_output, img_shape, scale_input_img, only_img_input, init_norm_kwargs, impala_kwargs and more that can be used to customize the model.",
        "type": "comment"
    },
    "260": {
        "file_id": 14,
        "content": "        timesteps=None,\n        use_pre_lstm_ln=True,  # Not needed for transformer\n        **unused_kwargs,\n    ):\n        super().__init__()\n        assert recurrence_type in [\n            \"multi_layer_lstm\",\n            \"multi_layer_bilstm\",\n            \"multi_masked_lstm\",\n            \"transformer\",\n            \"none\",\n        ]\n        active_reward_monitors = active_reward_monitors or {}\n        self.single_output = single_output\n        chans = tuple(int(impala_width * c) for c in impala_chans)\n        self.hidsize = hidsize\n        # Dense init kwargs replaces batchnorm/groupnorm with layernorm\n        self.init_norm_kwargs = init_norm_kwargs\n        self.dense_init_norm_kwargs = deepcopy(init_norm_kwargs)\n        if self.dense_init_norm_kwargs.get(\"group_norm_groups\", None) is not None:\n            self.dense_init_norm_kwargs.pop(\"group_norm_groups\", None)\n            self.dense_init_norm_kwargs[\"layer_norm\"] = True\n        if self.dense_init_norm_kwargs.get(\"batch_norm\", False):\n            self.dense_init_norm_kwargs.pop(\"batch_norm\", False)",
        "type": "code",
        "location": "/lib/policy.py:123-150"
    },
    "261": {
        "file_id": 14,
        "content": "The code defines a class with an __init__ method that takes various arguments, including the recurrence_type, active_reward_monitors, single_output, impala_width, impala_chans, hidsize, init_norm_kwargs and timesteps. It performs an assertion on the recurrence_type, initializes some variables and dictionaries, and defines a few more attributes based on these arguments.",
        "type": "comment"
    },
    "262": {
        "file_id": 14,
        "content": "            self.dense_init_norm_kwargs[\"layer_norm\"] = True\n        # Setup inputs\n        self.img_preprocess = ImgPreprocessing(img_statistics=img_statistics, scale_img=scale_input_img)\n        self.img_process = ImgObsProcess(\n            cnn_outsize=256,\n            output_size=hidsize,\n            inshape=img_shape,\n            chans=chans,\n            nblock=2,\n            dense_init_norm_kwargs=self.dense_init_norm_kwargs,\n            init_norm_kwargs=init_norm_kwargs,\n            first_conv_norm=first_conv_norm,\n            **impala_kwargs,\n        )\n        self.pre_lstm_ln = nn.LayerNorm(hidsize) if use_pre_lstm_ln else None\n        self.diff_obs_process = None\n        self.recurrence_type = recurrence_type\n        self.recurrent_layer = None\n        self.recurrent_layer = ResidualRecurrentBlocks(\n            hidsize=hidsize,\n            timesteps=timesteps,\n            recurrence_type=recurrence_type,\n            is_residual=recurrence_is_residual,\n            use_pointwise_layer=use_pointwise_layer,",
        "type": "code",
        "location": "/lib/policy.py:151-178"
    },
    "263": {
        "file_id": 14,
        "content": "Initializing layer norm for dense layers and setting up input processing components.",
        "type": "comment"
    },
    "264": {
        "file_id": 14,
        "content": "            pointwise_ratio=pointwise_ratio,\n            pointwise_use_activation=pointwise_use_activation,\n            attention_mask_style=attention_mask_style,\n            attention_heads=attention_heads,\n            attention_memory_size=attention_memory_size,\n            n_block=n_recurrence_layers,\n        )\n        self.lastlayer = FanInInitReLULayer(hidsize, hidsize, layer_type=\"linear\", **self.dense_init_norm_kwargs)\n        self.final_ln = th.nn.LayerNorm(hidsize)\n    def output_latent_size(self):\n        return self.hidsize\n    def forward(self, ob, state_in, context):\n        first = context[\"first\"]\n        x = self.img_preprocess(ob[\"img\"])\n        x = self.img_process(x)\n        if self.diff_obs_process:\n            processed_obs = self.diff_obs_process(ob[\"diff_goal\"])\n            x = processed_obs + x\n        if self.pre_lstm_ln is not None:\n            x = self.pre_lstm_ln(x)\n        if self.recurrent_layer is not None:\n            x, state_out = self.recurrent_layer(x, first, state_in)\n        else:",
        "type": "code",
        "location": "/lib/policy.py:179-208"
    },
    "265": {
        "file_id": 14,
        "content": "The code initializes a module with specified parameters including pointwise_ratio, pointwise_use_activation, attention_mask_style, attention_heads, attention_memory_size and n_block. Then it creates an instance of FanInInitReLULayer and LayerNorm for the last layer and final layer normalization respectively. It also defines a function output_latent_size to return the latent size, and another function forward which takes in observations, initial state, and context as input, performs image preprocessing and optional differential observation processing if specified, applies pre-LSTM normalization if present, then passes the processed data through the recurrent layer to obtain output x and updated state.",
        "type": "comment"
    },
    "266": {
        "file_id": 14,
        "content": "            state_out = state_in\n        x = F.relu(x, inplace=False)\n        x = self.lastlayer(x)\n        x = self.final_ln(x)\n        pi_latent = vf_latent = x\n        if self.single_output:\n            return pi_latent, state_out\n        return (pi_latent, vf_latent), state_out\n    def initial_state(self, batchsize):\n        if self.recurrent_layer:\n            return self.recurrent_layer.initial_state(batchsize)\n        else:\n            return None\nclass MinecraftAgentPolicy(nn.Module):\n    def __init__(self, action_space, policy_kwargs, pi_head_kwargs):\n        super().__init__()\n        self.net = MinecraftPolicy(**policy_kwargs)\n        self.action_space = action_space\n        self.value_head = self.make_value_head(self.net.output_latent_size())\n        self.pi_head = self.make_action_head(self.net.output_latent_size(), **pi_head_kwargs)\n    def make_value_head(self, v_out_size: int, norm_type: str = \"ewma\", norm_kwargs: Optional[Dict] = None):\n        return ScaledMSEHead(v_out_size, 1, norm_type=norm_type, norm_kwargs=norm_kwargs)",
        "type": "code",
        "location": "/lib/policy.py:209-238"
    },
    "267": {
        "file_id": 14,
        "content": "The code defines a class `MinecraftAgentPolicy` that inherits from `nn.Module`. It takes in an action space, policy kwargs, and pi_head kwargs as parameters during initialization. Inside the initialization, it creates a network `self.net` using `MinecraftPolicy`, a value head `self.value_head` using `make_value_head`, and a policy head `self.pi_head` using `make_action_head`. The code also defines a method `initial_state(batchsize)` that returns the initial state of the recurrent layer if it exists, otherwise it returns None.",
        "type": "comment"
    },
    "268": {
        "file_id": 14,
        "content": "    def make_action_head(self, pi_out_size: int, **pi_head_opts):\n        return make_action_head(self.action_space, pi_out_size, **pi_head_opts)\n    def initial_state(self, batch_size: int):\n        return self.net.initial_state(batch_size)\n    def reset_parameters(self):\n        super().reset_parameters()\n        self.net.reset_parameters()\n        self.pi_head.reset_parameters()\n        self.value_head.reset_parameters()\n    def forward(self, obs, first: th.Tensor, state_in):\n        if isinstance(obs, dict):\n            # We don't want to mutate the obs input.\n            obs = obs.copy()\n            # If special \"mask\" key is in obs,\n            # It's for masking the logits.\n            # We take it out (the network doesn't need it)\n            mask = obs.pop(\"mask\", None)\n        else:\n            mask = None\n        (pi_h, v_h), state_out = self.net(obs, state_in, context={\"first\": first})\n        pi_logits = self.pi_head(pi_h, mask=mask)\n        vpred = self.value_head(v_h)\n        return (pi_logits, vpred, None), state_out",
        "type": "code",
        "location": "/lib/policy.py:240-269"
    },
    "269": {
        "file_id": 14,
        "content": "This code defines a class that uses a neural network to make policy decisions. It includes methods for creating an action head, initializing the state, resetting parameters, and performing forward passes on input observations. The forward pass involves passing the observation through the network, extracting policy logits and value predictions using separate heads, and returning these outputs along with any updated state.",
        "type": "comment"
    },
    "270": {
        "file_id": 14,
        "content": "    def get_logprob_of_action(self, pd, action):\n        \"\"\"\n        Get logprob of taking action `action` given probability distribution\n        (see `get_gradient_for_action` to get this distribution)\n        \"\"\"\n        ac = tree_map(lambda x: x.unsqueeze(1), action)\n        log_prob = self.pi_head.logprob(ac, pd)\n        assert not th.isnan(log_prob).any()\n        return log_prob[:, 0]\n    def get_kl_of_action_dists(self, pd1, pd2):\n        \"\"\"\n        Get the KL divergence between two action probability distributions\n        \"\"\"\n        return self.pi_head.kl_divergence(pd1, pd2)\n    def get_output_for_observation(self, obs, state_in, first):\n        \"\"\"\n        Return gradient-enabled outputs for given observation.\n        Use `get_logprob_of_action` to get log probability of action\n        with the given probability distribution.\n        Returns:\n          - probability distribution given observation\n          - value prediction for given observation\n          - new state\n        \"\"\"\n        # We need to add a fictitious time dimension everywhere",
        "type": "code",
        "location": "/lib/policy.py:271-299"
    },
    "271": {
        "file_id": 14,
        "content": "This code defines three functions for handling actions and probabilities in a policy network. The first function `get_logprob_of_action` calculates the log probability of taking a given action based on the provided probability distribution. The second function `get_kl_of_action_dists` computes the KL divergence between two action probability distributions. Lastly, the `get_output_for_observation` function returns the probability distribution, value prediction, and new state for a given observation using the previous two functions.",
        "type": "comment"
    },
    "272": {
        "file_id": 14,
        "content": "        obs = tree_map(lambda x: x.unsqueeze(1), obs)\n        first = first.unsqueeze(1)\n        (pd, vpred, _), state_out = self(obs=obs, first=first, state_in=state_in)\n        return pd, self.value_head.denormalize(vpred)[:, 0], state_out\n    @th.no_grad()\n    def act(self, obs, first, state_in, stochastic: bool = True, taken_action=None, return_pd=False):\n        # We need to add a fictitious time dimension everywhere\n        obs = tree_map(lambda x: x.unsqueeze(1), obs)\n        first = first.unsqueeze(1)\n        (pd, vpred, _), state_out = self(obs=obs, first=first, state_in=state_in)\n        if taken_action is None:\n            ac = self.pi_head.sample(pd, deterministic=not stochastic)\n        else:\n            ac = tree_map(lambda x: x.unsqueeze(1), taken_action)\n        log_prob = self.pi_head.logprob(ac, pd)\n        assert not th.isnan(log_prob).any()\n        # After unsqueezing, squeeze back to remove fictitious time dimension\n        result = {\"log_prob\": log_prob[:, 0], \"vpred\": self.value_head.denormalize(vpred)[:, 0]}",
        "type": "code",
        "location": "/lib/policy.py:300-323"
    },
    "273": {
        "file_id": 14,
        "content": "Code is adding a time dimension to the observations and first state, then passing them through the model to get policies (pd), value predictions (vpred), and update the state. If a taken action is provided, it uses that for the current step instead of sampling from the policy. It calculates the log probability of the taken action and stores the results in a dictionary with keys \"log_prob\" and \"vpred\". The time dimension is removed after calculations are done.",
        "type": "comment"
    },
    "274": {
        "file_id": 14,
        "content": "        if return_pd:\n            result[\"pd\"] = tree_map(lambda x: x[:, 0], pd)\n        ac = tree_map(lambda x: x[:, 0], ac)\n        return ac, state_out, result\n    @th.no_grad()\n    def v(self, obs, first, state_in):\n        \"\"\"Predict value for a given mdp observation\"\"\"\n        obs = tree_map(lambda x: x.unsqueeze(1), obs)\n        first = first.unsqueeze(1)\n        (pd, vpred, _), state_out = self(obs=obs, first=first, state_in=state_in)\n        # After unsqueezing, squeeze back\n        return self.value_head.denormalize(vpred)[:, 0]\nclass InverseActionNet(MinecraftPolicy):\n    \"\"\"\n    Args:\n        conv3d_params: PRE impala 3D CNN params. They are just passed into th.nn.Conv3D.\n    \"\"\"\n    def __init__(\n        self,\n        hidsize=512,\n        conv3d_params=None,\n        **MCPoliy_kwargs,\n    ):\n        super().__init__(\n            hidsize=hidsize,\n            # If we're using 3dconv, then we normalize entire impala otherwise don't\n            # normalize the first impala layer since we normalize the input",
        "type": "code",
        "location": "/lib/policy.py:324-357"
    },
    "275": {
        "file_id": 14,
        "content": "This code defines a class called \"InverseActionNet\" that inherits from another class named \"MinecraftPolicy\". The class has an initializer which takes parameters for hidden size, 3D convolution parameters, and any other arguments passed to the parent class. It also contains two methods: \"policy\" and \"v\".\n\nThe \"policy\" method calculates the policy distribution (pd) and the value prediction (vpred) for a given observation (obs). It returns the pd, vpred, and an additional state_out. If return_pd is True, it also returns the first element of each vector in the pd array by using tree_map lambda function.\n\nThe \"v\" method predicts the value for a given MDP observation. It takes obs, first, and state_in as input parameters. After unsqueezing the obs and first variables, it calls the parent class's __call__ method to get pd, vpred, and state_out. Finally, it returns the denormalized vpred value of the first element in each vector by using self.value_head.denormalize function.",
        "type": "comment"
    },
    "276": {
        "file_id": 14,
        "content": "            first_conv_norm=conv3d_params is not None,\n            **MCPoliy_kwargs,\n        )\n        self.conv3d_layer = None\n        if conv3d_params is not None:\n            # 3D conv is the first layer, so don't normalize its input\n            conv3d_init_params = deepcopy(self.init_norm_kwargs)\n            conv3d_init_params[\"group_norm_groups\"] = None\n            conv3d_init_params[\"batch_norm\"] = False\n            self.conv3d_layer = FanInInitReLULayer(\n                layer_type=\"conv3d\",\n                log_scope=\"3d_conv\",\n                **conv3d_params,\n                **conv3d_init_params,\n            )\n    def forward(self, ob, state_in, context):\n        first = context[\"first\"]\n        x = self.img_preprocess(ob[\"img\"])\n        # Conv3D Prior to Impala\n        if self.conv3d_layer is not None:\n            x = self._conv3d_forward(x)\n        # Impala Stack\n        x = self.img_process(x)\n        if self.recurrent_layer is not None:\n            x, state_out = self.recurrent_layer(x, first, state_in)",
        "type": "code",
        "location": "/lib/policy.py:358-386"
    },
    "277": {
        "file_id": 14,
        "content": "This code initializes a 3D convolution layer if the `conv3d_params` is not None. It also sets the initialization parameters for the 3D conv layer differently to avoid normalization of its input. The forward function applies the 3D convolution (if available) before processing the image stack.",
        "type": "comment"
    },
    "278": {
        "file_id": 14,
        "content": "        x = F.relu(x, inplace=False)\n        pi_latent = self.lastlayer(x)\n        pi_latent = self.final_ln(x)\n        return (pi_latent, None), state_out\n    def _conv3d_forward(self, x):\n        # Convert from (B, T, H, W, C) -> (B, H, W, C, T)\n        x = transpose(x, \"bthwc\", \"bcthw\")\n        new_x = []\n        for mini_batch in th.split(x, 1):\n            new_x.append(self.conv3d_layer(mini_batch))\n        x = th.cat(new_x)\n        # Convert back\n        x = transpose(x, \"bcthw\", \"bthwc\")\n        return x\nclass InverseActionPolicy(nn.Module):\n    def __init__(\n        self,\n        action_space,\n        pi_head_kwargs=None,\n        idm_net_kwargs=None,\n    ):\n        super().__init__()\n        self.action_space = action_space\n        self.net = InverseActionNet(**idm_net_kwargs)\n        pi_out_size = self.net.output_latent_size()\n        pi_head_kwargs = {} if pi_head_kwargs is None else pi_head_kwargs\n        self.pi_head = self.make_action_head(pi_out_size=pi_out_size, **pi_head_kwargs)\n    def make_action_head(self, **kwargs):",
        "type": "code",
        "location": "/lib/policy.py:388-424"
    },
    "279": {
        "file_id": 14,
        "content": "The code defines a class `InverseActionPolicy` that inherits from `nn.Module`. This class represents an inverse action policy for a reinforcement learning model. It consists of two components: a network (`self.net`) and a policy head (`self.pi_head`). The network is responsible for mapping observations to a latent space, while the policy head maps the latent representation to a distribution over actions.\n\nThe `__init__` method initializes the instance of the class by setting the action space, creating an instance of the `InverseActionNet`, and then creating the policy head based on the specified output size from the network and any additional keyword arguments provided.\n\nThe `_conv3d_forward` function is a helper function that performs 3D convolution on input data and returns the result. It transposes the input tensor, applies a series of 1D convolutions along different axes, and then transposes the resulting tensor back to the original format.\n\nThe `_policy_and_value` method calculates the policy and value for an input observation by passing it through the network and policy head, applying a ReLU activation function, and normalizing the output distribution. It also returns the current internal state of the module.",
        "type": "comment"
    },
    "280": {
        "file_id": 14,
        "content": "        return make_action_head(self.action_space, **kwargs)\n    def reset_parameters(self):\n        super().reset_parameters()\n        self.net.reset_parameters()\n        self.pi_head.reset_parameters()\n    def forward(self, obs, first: th.Tensor, state_in, **kwargs):\n        if isinstance(obs, dict):\n            # We don't want to mutate the obs input.\n            obs = obs.copy()\n            # If special \"mask\" key is in obs,\n            # It's for masking the logits.\n            # We take it out (the network doesn't need it)\n            mask = obs.pop(\"mask\", None)\n        else:\n            mask = None\n        (pi_h, _), state_out = self.net(obs, state_in=state_in, context={\"first\": first}, **kwargs)\n        pi_logits = self.pi_head(pi_h, mask=mask)\n        return (pi_logits, None, None), state_out\n    @th.no_grad()\n    def predict(\n        self,\n        obs,\n        deterministic: bool = True,\n        **kwargs,\n    ):\n        (pd, _, _), state_out = self(obs=obs, **kwargs)\n        ac = self.pi_head.sample(pd, deterministic=deterministic)",
        "type": "code",
        "location": "/lib/policy.py:425-457"
    },
    "281": {
        "file_id": 14,
        "content": "This code defines a policy class for training reinforcement learning models. It has methods to reset the model's parameters, forward pass to obtain action-value logits and state, and a deterministic prediction method. The code uses PyTorch for tensor operations.",
        "type": "comment"
    },
    "282": {
        "file_id": 14,
        "content": "        log_prob = self.pi_head.logprob(ac, pd)\n        assert not th.isnan(log_prob).any()\n        result = {\"log_prob\": log_prob, \"pd\": pd}\n        return ac, state_out, result\n    def initial_state(self, batch_size: int):\n        return self.net.initial_state(batch_size)",
        "type": "code",
        "location": "/lib/policy.py:458-467"
    },
    "283": {
        "file_id": 14,
        "content": "The code computes the log probability of actions using the pi_head, checks for NaN values, and returns a dictionary containing the log_probability and pd. It also includes functions for initializing the state based on batch size.",
        "type": "comment"
    },
    "284": {
        "file_id": 15,
        "content": "/lib/scaled_mse_head.py",
        "type": "filepath"
    },
    "285": {
        "file_id": 15,
        "content": "The code defines a ScaledMSEHead class for a linear output layer, scales targets to N(0, 1), and calculates MSE loss between normalized predictions and denormalized target values in a normalized space.",
        "type": "summary"
    },
    "286": {
        "file_id": 15,
        "content": "from typing import Dict, Optional\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.nn.init as init\nfrom lib.action_head import fan_in_linear\nfrom lib.normalize_ewma import NormalizeEwma\nclass ScaledMSEHead(nn.Module):\n    \"\"\"\n    Linear output layer that scales itself so that targets are always normalized to N(0, 1)\n    \"\"\"\n    def __init__(\n        self, input_size: int, output_size: int, norm_type: Optional[str] = \"ewma\", norm_kwargs: Optional[Dict] = None\n    ):\n        super().__init__()\n        self.input_size = input_size\n        self.output_size = output_size\n        self.norm_type = norm_type\n        self.linear = nn.Linear(self.input_size, self.output_size)\n        norm_kwargs = {} if norm_kwargs is None else norm_kwargs\n        self.normalizer = NormalizeEwma(output_size, **norm_kwargs)\n    def reset_parameters(self):\n        init.orthogonal_(self.linear.weight)\n        fan_in_linear(self.linear)\n        self.normalizer.reset_parameters()\n    def forward(self, input_data):\n        return self.linear(input_data)",
        "type": "code",
        "location": "/lib/scaled_mse_head.py:1-35"
    },
    "287": {
        "file_id": 15,
        "content": "This code defines a ScaledMSEHead class which is a linear output layer. It scales itself so that targets are always normalized to N(0, 1). The input size, output size, normalization type (ewma), and normalization kwargs can be set upon instantiation. The reset_parameters function initializes the weights with orthogonal initialization and resets the normalizer's parameters. Forward function passes input data through a linear layer.",
        "type": "comment"
    },
    "288": {
        "file_id": 15,
        "content": "    def loss(self, prediction, target):\n        \"\"\"\n        Calculate the MSE loss between output and a target.\n        'Prediction' has to be normalized while target is denormalized.\n        Loss is calculated in a 'normalized' space.\n        \"\"\"\n        return F.mse_loss(prediction, self.normalizer(target), reduction=\"mean\")\n    def denormalize(self, input_data):\n        \"\"\"Convert input value from a normalized space into the original one\"\"\"\n        return self.normalizer.denormalize(input_data)\n    def normalize(self, input_data):\n        return self.normalizer(input_data)",
        "type": "code",
        "location": "/lib/scaled_mse_head.py:37-50"
    },
    "289": {
        "file_id": 15,
        "content": "This code defines a loss function for MSE (Mean Squared Error) and normalization/denormalization functions. It calculates the MSE loss between normalized prediction and denormalized target values in a normalized space, and converts input values from normalized to original space.",
        "type": "comment"
    },
    "290": {
        "file_id": 16,
        "content": "/lib/torch_util.py",
        "type": "filepath"
    },
    "291": {
        "file_id": 16,
        "content": "The code handles libraries, device defaults, tensor and layer functions, CUDA availability, LayerNorm creation, dimension flattening, sequential application of layers, parameter loading from multiple paths, and function state saving. The function takes a dtype string and converts it to PyTorch tensor data type, with an index function for batched broadcasting 'xi' along specified 'gather_dim'.",
        "type": "summary"
    },
    "292": {
        "file_id": 16,
        "content": "import functools\nimport itertools\nimport math\nimport os\nimport pickle\nimport re\nimport subprocess\nimport tempfile\nfrom contextlib import contextmanager\nfrom hashlib import md5, sha1\nimport numpy as np\nimport torch as th\nimport torch.distributed as dist\nimport torch.distributions as dis\nimport torch.nn.functional as F\nfrom torch import nn\nimport lib.tree_util as tree_util\nfrom lib import misc\ndef contextmanager_to_decorator(cm):\n    def decorator(fn):\n        @functools.wraps(fn)\n        def newfn(*args, **kwargs):\n            with cm():\n                return fn(*args, **kwargs)\n        return newfn\n    return decorator\ndef have_cuda():\n    return th.has_cuda\ndef default_device_type():\n    return \"cuda\" if have_cuda() else \"cpu\"\nno_grad = contextmanager_to_decorator(th.no_grad)\nDEFAULT_DEVICE = th.device(type=default_device_type())\ndef set_default_torch_device(device):\n    global DEFAULT_DEVICE\n    DEFAULT_DEVICE = th.device(device)\ndef dev():\n    return DEFAULT_DEVICE\ndef zeros(*args, **kwargs):\n    return th.zeros(*args, **kwargs, device=dev())",
        "type": "code",
        "location": "/lib/torch_util.py:1-57"
    },
    "293": {
        "file_id": 16,
        "content": "This code imports various libraries, defines a function to convert context managers into decorators, checks if CUDA is available, sets the default device as either CUDA or CPU depending on availability, and then defines functions for creating tensors with zeros.",
        "type": "comment"
    },
    "294": {
        "file_id": 16,
        "content": "def ones(*args, **kwargs):\n    return th.ones(*args, **kwargs, device=dev())\ndef arange(*args, **kwargs):\n    return th.arange(*args, **kwargs, device=dev())\ndef NormedLinear(*args, scale=1.0, dtype=th.float32, **kwargs):\n    \"\"\"\n    nn.Linear but with normalized fan-in init\n    \"\"\"\n    dtype = parse_dtype(dtype)\n    if dtype == th.float32:\n        out = nn.Linear(*args, **kwargs)\n    elif dtype == th.float16:\n        out = LinearF16(*args, **kwargs)\n    else:\n        raise ValueError(dtype)\n    out.weight.data *= scale / out.weight.norm(dim=1, p=2, keepdim=True)\n    if kwargs.get(\"bias\", True):\n        out.bias.data *= 0\n    return out\nclass LinearF16(nn.Linear):\n    def forward(self, x):\n        return F.linear(x, self.weight.half(), self.bias.half() if self.bias is not None else None)\nclass LayerNormF16(nn.LayerNorm):\n    def forward(self, x):\n        return F.layer_norm(x, self.normalized_shape, self.weight.half(), self.bias.half(), self.eps)\ndef LayerNorm(*args, dtype=th.float32, **kwargs):\n    dtype = parse_dtype(dtype)",
        "type": "code",
        "location": "/lib/torch_util.py:60-96"
    },
    "295": {
        "file_id": 16,
        "content": "Code defines functions for creating normalized Linear layers, F16 linear and LayerNorm modules. It also includes a utility function to create Tensor objects on the device specified by dev() function.",
        "type": "comment"
    },
    "296": {
        "file_id": 16,
        "content": "    if dtype == th.float32:\n        out = nn.LayerNorm(*args, **kwargs)\n    elif dtype == th.float16:\n        out = LayerNormF16(*args, **kwargs)\n    else:\n        raise ValueError(dtype)\n    out.weight.no_scale = True\n    return out\ndef flatten_image(x):\n    \"\"\"\n    Flattens last three dims\n    \"\"\"\n    *batch_shape, h, w, c = x.shape\n    return x.reshape((*batch_shape, h * w * c))\ndef sequential(layers, x, *args, diag_name=None, use_checkpoint=False):\n    for (i, layer) in enumerate(layers):\n        x = layer(x, *args)\n    return x\n@no_grad\ndef load_average_with_metadata(paths, overrides):\n    n_models = len(paths)\n    model, metadata = load_with_metadata(paths[0], overrides=overrides)\n    for p in model.parameters():\n        p.mul_(1 / n_models)\n    for p in paths[1:]:\n        new_model, _ = load_with_metadata(p, overrides=overrides)\n        for (n1, p1), (n2, p2) in misc.safezip(model.named_parameters(), new_model.named_parameters()):\n            assert n1 == n2, f\"names {n1} and {n2} don't match\"\n            p1.add_(p2.mul_(1 / n_models))",
        "type": "code",
        "location": "/lib/torch_util.py:97-131"
    },
    "297": {
        "file_id": 16,
        "content": "- Code snippets from \"Video-Pre-Training/lib/torch_util.py\":\n- 96-130: LayerNorm creation depending on dtype (float32, float16), sets weight no_scale to True.\n- flatten_image: Flattens the last three dimensions of a tensor.\n- sequential: Applies layers in order to input tensor, returns final result.\n- load_average_with_metadata: Loads models from multiple paths and averages their parameters.",
        "type": "comment"
    },
    "298": {
        "file_id": 16,
        "content": "    return model, metadata\ndef save_kwargs(fn):\n    \"\"\"\n    This decorator passes through the user-provided kwargs and adds one more, called\n    save_kwargs, mapping to {\"create_fn\" : name_of_decorated_fn, \"kwargs\" : other_kwargs}\n    You put on this decorator on a function that creates a pytorch module. This will\n    save the kwargs and the function that was used to create the module.\n    This lets us restore the model state later.\n    \"\"\"\n    @functools.wraps(fn)\n    def wrapper(**kwargs):\n        if \"save_kwargs\" in kwargs:\n            return fn(**kwargs)\n        else:\n            sk = {**kwargs, \"create_fn\": f\"{fn.__module__}:{fn.__name__}\"}\n            return fn(save_kwargs=sk, **kwargs)\n    return wrapper\ndef parse_dtype(x):\n    if isinstance(x, th.dtype):\n        return x\n    elif isinstance(x, str):\n        if x == \"float32\" or x == \"float\":\n            return th.float32\n        elif x == \"float64\" or x == \"double\":\n            return th.float64\n        elif x == \"float16\" or x == \"half\":\n            return th.float16",
        "type": "code",
        "location": "/lib/torch_util.py:132-165"
    },
    "299": {
        "file_id": 16,
        "content": "The code defines a decorator, save_kwargs, that allows saving the function and its arguments used to create a PyTorch module, enabling later restoration of the model state. It also includes a utility function, parse_dtype, for converting data types into their equivalent PyTorch dtype objects.",
        "type": "comment"
    }
}