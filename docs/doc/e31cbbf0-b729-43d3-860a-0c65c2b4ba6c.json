{
    "summary": "The ImpalaCNN architecture is created with optional group normalization, allowing for customizable input shape, downsample stacks, output hidden size, and residual blocks per stack. It inherits from a base class and utilizes 2D convolutional layers for multi-stack classification models.",
    "details": [
        {
            "comment": "This code defines a CnnBasicBlock class for ImpalaCNN, which is a residual basic block that preserves the number of input channels and the shape. It uses FanInInitReLULayer for the convolutional layers and allows adjusting weight initialization scale, log scope, and initialization normalization parameters.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":0-41",
            "content": "import math\nfrom copy import deepcopy\nfrom typing import Dict, List, Optional\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom lib import misc\nfrom lib import torch_util as tu\nfrom lib.util import FanInInitReLULayer\nclass CnnBasicBlock(nn.Module):\n    \"\"\"\n    Residual basic block, as in ImpalaCNN. Preserves channel number and shape\n    :param inchan: number of input channels\n    :param init_scale: weight init scale multiplier\n    \"\"\"\n    def __init__(\n        self,\n        inchan: int,\n        init_scale: float = 1,\n        log_scope=\"\",\n        init_norm_kwargs: Dict = {},\n        **kwargs,\n    ):\n        super().__init__()\n        self.inchan = inchan\n        s = math.sqrt(init_scale)\n        self.conv0 = FanInInitReLULayer(\n            self.inchan,\n            self.inchan,\n            kernel_size=3,\n            padding=1,\n            init_scale=s,\n            log_scope=f\"{log_scope}/conv0\",\n            **init_norm_kwargs,\n        )\n        self.conv1 = FanInInitReLULayer(\n            self.inchan,\n            self.inchan,"
        },
        {
            "comment": "This code defines two classes: `ImpalaCnnConv1d` and `CnnDownStack`. The `ImpalaCnnConv1d` class represents a 1-dimensional convolutional layer with specific parameters, while the `CnnDownStack` class is a stack of downsampling blocks using the `ImpalaCnnConv1d` as the base. These classes are used for image classification tasks following the Impala CNN architecture.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":42-77",
            "content": "            kernel_size=3,\n            padding=1,\n            init_scale=s,\n            log_scope=f\"{log_scope}/conv1\",\n            **init_norm_kwargs,\n        )\n    def forward(self, x):\n        x = x + self.conv1(self.conv0(x))\n        return x\nclass CnnDownStack(nn.Module):\n    \"\"\"\n    Downsampling stack from Impala CNN.\n    :param inchan: number of input channels\n    :param nblock: number of residual blocks after downsampling\n    :param outchan: number of output channels\n    :param init_scale: weight init scale multiplier\n    :param pool: if true, downsample with max pool\n    :param post_pool_groups: if not None, normalize with group norm with this many groups\n    :param kwargs: remaining kwargs are passed into the blocks and layers\n    \"\"\"\n    name = \"Impala_CnnDownStack\"\n    def __init__(\n        self,\n        inchan: int,\n        nblock: int,\n        outchan: int,\n        init_scale: float = 1,\n        pool: bool = True,\n        post_pool_groups: Optional[int] = None,\n        log_scope: str = \"\",\n        init_norm_kwargs: Dict = {},"
        },
        {
            "comment": "This code initializes a CNN architecture with optional group normalization. It takes parameters such as input and output channels, pooling size, and whether to use group normalization for the first convolution layer or not. The code also includes a list of blocks, where each block is an instance of CnnBasicBlock.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":78-106",
            "content": "        first_conv_norm=False,\n        **kwargs,\n    ):\n        super().__init__()\n        self.inchan = inchan\n        self.outchan = outchan\n        self.pool = pool\n        first_conv_init_kwargs = deepcopy(init_norm_kwargs)\n        if not first_conv_norm:\n            first_conv_init_kwargs[\"group_norm_groups\"] = None\n            first_conv_init_kwargs[\"batch_norm\"] = False\n        self.firstconv = FanInInitReLULayer(\n            inchan,\n            outchan,\n            kernel_size=3,\n            padding=1,\n            log_scope=f\"{log_scope}/firstconv\",\n            **first_conv_init_kwargs,\n        )\n        self.post_pool_groups = post_pool_groups\n        if post_pool_groups is not None:\n            self.n = nn.GroupNorm(post_pool_groups, outchan)\n        self.blocks = nn.ModuleList(\n            [\n                CnnBasicBlock(\n                    outchan,\n                    init_scale=init_scale / math.sqrt(nblock),\n                    log_scope=f\"{log_scope}/block{i}\",\n                    init_norm_kwargs=init_norm_kwargs,"
        },
        {
            "comment": "This code defines a class for an ImpalaCNN model, which is a residual convolutional neural network. The constructor takes input image shape, number of residual downsample stacks, output hidden size, and number of residual blocks per stack as parameters. The forward method performs the forward pass through the network, and the output_shape method returns the expected output shape given the input shape.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":107-138",
            "content": "                    **kwargs,\n                )\n                for i in range(nblock)\n            ]\n        )\n    def forward(self, x):\n        x = self.firstconv(x)\n        if self.pool:\n            x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n            if self.post_pool_groups is not None:\n                x = self.n(x)\n        x = tu.sequential(self.blocks, x, diag_name=self.name)\n        return x\n    def output_shape(self, inshape):\n        c, h, w = inshape\n        assert c == self.inchan\n        if self.pool:\n            return (self.outchan, (h + 1) // 2, (w + 1) // 2)\n        else:\n            return (self.outchan, h, w)\nclass ImpalaCNN(nn.Module):\n    \"\"\"\n    :param inshape: input image shape (height, width, channels)\n    :param chans: number of residual downsample stacks. Each element is the number of\n        filters per convolution in the stack\n    :param outsize: output hidden size\n    :param nblock: number of residual blocks per stack. Each block has 2 convs and a residual\n    :param init_norm_kwargs: arguments to be passed to convolutional layers. Options can be found"
        },
        {
            "comment": "This code defines a class called \"ImpalaCNN\" which inherits from the base class. It takes in parameters such as input shape, number of channels, output size, number of blocks, initialization arguments for normalization layers, and additional keyword arguments. The class initializes a list of CNN downstack modules and sets their configurations based on the input parameters.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":139-170",
            "content": "        in ypt.model.util:FanInInitReLULayer\n    :param dense_init_norm_kwargs: arguments to be passed to convolutional layers. Options can be found\n        in ypt.model.util:FanInInitReLULayer\n    :param kwargs: remaining kwargs are passed into the CnnDownStacks\n    \"\"\"\n    name = \"ImpalaCNN\"\n    def __init__(\n        self,\n        inshape: List[int],\n        chans: List[int],\n        outsize: int,\n        nblock: int,\n        init_norm_kwargs: Dict = {},\n        dense_init_norm_kwargs: Dict = {},\n        first_conv_norm=False,\n        **kwargs,\n    ):\n        super().__init__()\n        h, w, c = inshape\n        curshape = (c, h, w)\n        self.stacks = nn.ModuleList()\n        for i, outchan in enumerate(chans):\n            stack = CnnDownStack(\n                curshape[0],\n                nblock=nblock,\n                outchan=outchan,\n                init_scale=math.sqrt(len(chans)),\n                log_scope=f\"downstack{i}\",\n                init_norm_kwargs=init_norm_kwargs,\n                first_conv_norm=first_conv_norm if i == 0 else True,"
        },
        {
            "comment": "This code initializes a CNN model with multiple stacked 2D convolutional layers. The output of each stack is used as input to the next stack until the final dense layer for classification.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/impala_cnn.py\":171-194",
            "content": "                **kwargs,\n            )\n            self.stacks.append(stack)\n            curshape = stack.output_shape(curshape)\n        self.dense = FanInInitReLULayer(\n            misc.intprod(curshape),\n            outsize,\n            layer_type=\"linear\",\n            log_scope=\"imapala_final_dense\",\n            init_scale=1.4,\n            **dense_init_norm_kwargs,\n        )\n        self.outsize = outsize\n    def forward(self, x):\n        b, t = x.shape[:-3]\n        x = x.reshape(b * t, *x.shape[-3:])\n        x = misc.transpose(x, \"bhwc\", \"bchw\")\n        x = tu.sequential(self.stacks, x, diag_name=self.name)\n        x = x.reshape(b, t, *x.shape[1:])\n        x = tu.flatten_image(x)\n        x = self.dense(x)\n        return x"
        }
    ]
}