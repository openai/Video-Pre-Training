{
    "summary": "The code includes Minecraft action classes with quantization schemes and an ActionTransformer, along with three functions for mapping item IDs to names and converting environment data to policy format.",
    "details": [
        {
            "comment": "This code defines classes for various action types and a camera quantizer in the context of Minecraft gameplay. The Buttons class represents different action buttons like attack, jump, inventory, etc. SyntheticButtons includes composite/scripted actions. QuantizationScheme has options for linear or mu-law quantization. CameraQuantizer is responsible for discretizing and undiscretizing continuous camera input (pitch and yaw).",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":0-53",
            "content": "import attr\nimport minerl.herobraine.hero.mc as mc\nimport numpy as np\nfrom lib.minecraft_util import store_args\nclass Buttons:\n    ATTACK = \"attack\"\n    BACK = \"back\"\n    FORWARD = \"forward\"\n    JUMP = \"jump\"\n    LEFT = \"left\"\n    RIGHT = \"right\"\n    SNEAK = \"sneak\"\n    SPRINT = \"sprint\"\n    USE = \"use\"\n    DROP = \"drop\"\n    INVENTORY = \"inventory\"\n    ALL = [\n        ATTACK,\n        BACK,\n        FORWARD,\n        JUMP,\n        LEFT,\n        RIGHT,\n        SNEAK,\n        SPRINT,\n        USE,\n        DROP,\n        INVENTORY,\n    ] + [f\"hotbar.{i}\" for i in range(1, 10)]\nclass SyntheticButtons:\n    # Composite / scripted actions\n    CHANNEL_ATTACK = \"channel-attack\"\n    ALL = [CHANNEL_ATTACK]\nclass QuantizationScheme:\n    LINEAR = \"linear\"\n    MU_LAW = \"mu_law\"\n@attr.s(auto_attribs=True)\nclass CameraQuantizer:\n    \"\"\"\n    A camera quantizer that discretizes and undiscretizes a continuous camera input with y (pitch) and x (yaw) components.\n    Parameters:\n    - camera_binsize: The size of the bins used for quantization. In case of mu-law quantization, it corresponds to the average binsize."
        },
        {
            "comment": "This code defines two quantization schemes for camera actions: linear and mu-law. It also provides reference values for the mu parameter based on maxval and desired max_precision for mu-law encoding.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":54-67",
            "content": "    - camera_maxval: The maximum value of the camera action.\n    - quantization_scheme: The quantization scheme to use. Currently, two quantization schemes are supported:\n    - Linear quantization (default): Camera actions are split uniformly into discrete bins\n    - Mu-law quantization: Transforms the camera action using mu-law encoding (https://en.wikipedia.org/wiki/%CE%9C-law_algorithm)\n    followed by the same quantization scheme used by the linear scheme.\n    - mu: Mu is the parameter that defines the curvature of the mu-law encoding. Higher values of\n    mu will result in a sharper transition near zero. Below are some reference values listed\n    for choosing mu given a constant maxval and a desired max_precision value.\n    maxval = 10 | max_precision = 0.5  | \u03bc \u2248 2.93826\n    maxval = 10 | max_precision = 0.4  | \u03bc \u2248 4.80939\n    maxval = 10 | max_precision = 0.25 | \u03bc \u2248 11.4887\n    maxval = 20 | max_precision = 0.5  | \u03bc \u2248 2.7\n    maxval = 20 | max_precision = 0.4  | \u03bc \u2248 4.39768\n    maxval = 20 | max_precision = 0.25 | \u03bc \u2248 10.3194"
        },
        {
            "comment": "This code defines a class with properties for camera max value, bin size, quantization scheme (linear or Mu-Law), and mu value. The discretize method takes in xy coordinates, clips them within the camera range, applies the specified quantization scheme to discretize the values, and returns the rounded values as integers. The undiscretize method takes in discretized values and converts them back to their original continuous representation by multiplying with the bin size and subtracting the camera max value.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":68-94",
            "content": "    maxval = 40 | max_precision = 0.5  | \u03bc \u2248 2.60780\n    maxval = 40 | max_precision = 0.4  | \u03bc \u2248 4.21554\n    maxval = 40 | max_precision = 0.25 | \u03bc \u2248 9.81152\n    \"\"\"\n    camera_maxval: int\n    camera_binsize: int\n    quantization_scheme: str = attr.ib(\n        default=QuantizationScheme.LINEAR,\n        validator=attr.validators.in_([QuantizationScheme.LINEAR, QuantizationScheme.MU_LAW]),\n    )\n    mu: float = attr.ib(default=5)\n    def discretize(self, xy):\n        xy = np.clip(xy, -self.camera_maxval, self.camera_maxval)\n        if self.quantization_scheme == QuantizationScheme.MU_LAW:\n            xy = xy / self.camera_maxval\n            v_encode = np.sign(xy) * (np.log(1.0 + self.mu * np.abs(xy)) / np.log(1.0 + self.mu))\n            v_encode *= self.camera_maxval\n            xy = v_encode\n        # Quantize using linear scheme\n        return np.round((xy + self.camera_maxval) / self.camera_binsize).astype(np.int64)\n    def undiscretize(self, xy):\n        xy = xy * self.camera_binsize - self.camera_maxval"
        },
        {
            "comment": "This code defines a class called `ActionTransformer` that transforms actions between internal arrays and the MinerL environment format. It includes methods for discretizing and undiscretizing camera data, as well as calculating a zero bin value based on camera binsize. If the quantization scheme is set to \"mu_law\", it applies the mu-law quantization method to the input data.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":96-129",
            "content": "        if self.quantization_scheme == QuantizationScheme.MU_LAW:\n            xy = xy / self.camera_maxval\n            v_decode = np.sign(xy) * (1.0 / self.mu) * ((1.0 + self.mu) ** np.abs(xy) - 1.0)\n            v_decode *= self.camera_maxval\n            xy = v_decode\n        return xy\nclass ActionTransformer:\n    \"\"\"Transforms actions between internal array and minerl env format.\"\"\"\n    @store_args\n    def __init__(\n        self,\n        camera_maxval=10,\n        camera_binsize=2,\n        camera_quantization_scheme=\"linear\",\n        camera_mu=5,\n    ):\n        self.quantizer = CameraQuantizer(\n            camera_maxval=camera_maxval,\n            camera_binsize=camera_binsize,\n            quantization_scheme=camera_quantization_scheme,\n            mu=camera_mu,\n        )\n    def camera_zero_bin(self):\n        return self.camera_maxval // self.camera_binsize\n    def discretize_camera(self, xy):\n        return self.quantizer.discretize(xy)\n    def undiscretize_camera(self, pq):\n        return self.quantizer.undiscretize(pq)"
        },
        {
            "comment": "The code contains three functions:\n\n1. item_embed_id_to_name(): This function converts an item ID to its name using the mc.MINERL_ITEM_MAP dictionary.\n2. dict_to_numpy(): This function transforms environment format data to policy output format, creating a dictionary \"act\" containing buttons and camera values in numpy array format. If human-spaces is False, it adds synthetic_buttons, place, equip, and craft values as well.\n3. numpy_to_dict(): This function converts numpy policy output to an environment-compatible format, ensuring the buttons shape matches the expected size.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":131-159",
            "content": "    def item_embed_id_to_name(self, item_id):\n        return mc.MINERL_ITEM_MAP[item_id]\n    def dict_to_numpy(self, acs):\n        \"\"\"\n        Env format to policy output format.\n        \"\"\"\n        act = {\n            \"buttons\": np.stack([acs.get(k, 0) for k in Buttons.ALL], axis=-1),\n            \"camera\": self.discretize_camera(acs[\"camera\"]),\n        }\n        if not self.human_spaces:\n            act.update(\n                {\n                    \"synthetic_buttons\": np.stack([acs[k] for k in SyntheticButtons.ALL], axis=-1),\n                    \"place\": self.item_embed_name_to_id(acs[\"place\"]),\n                    \"equip\": self.item_embed_name_to_id(acs[\"equip\"]),\n                    \"craft\": self.item_embed_name_to_id(acs[\"craft\"]),\n                }\n            )\n        return act\n    def numpy_to_dict(self, acs):\n        \"\"\"\n        Numpy policy output to env-compatible format.\n        \"\"\"\n        assert acs[\"buttons\"].shape[-1] == len(\n            Buttons.ALL\n        ), f\"Mismatched actions: {acs}; expected {len(Buttons.ALL)}:\\n(  {Buttons.ALL})\""
        },
        {
            "comment": "The code defines three methods: \"undiscretize_camera\", \"numpy_to_dict\", and \"discretize_camera\". It converts a camera array to its undiscretized form, converts numpy arrays to dictionaries, and converts an undiscretized camera array back into discretized form, respectively.",
            "location": "\"/media/root/Toshiba XG3/works/Video-Pre-Training/docs/src/lib/actions.py\":160-177",
            "content": "        out = {name: acs[\"buttons\"][..., i] for (i, name) in enumerate(Buttons.ALL)}\n        out[\"camera\"] = self.undiscretize_camera(acs[\"camera\"])\n        return out\n    def policy2env(self, acs):\n        acs = self.numpy_to_dict(acs)\n        return acs\n    def env2policy(self, acs):\n        nbatch = acs[\"camera\"].shape[0]\n        dummy = np.zeros((nbatch,))\n        out = {\n            \"camera\": self.discretize_camera(acs[\"camera\"]),\n            \"buttons\": np.stack([acs.get(k, dummy) for k in Buttons.ALL], axis=-1),\n        }\n        return out"
        }
    ]
}